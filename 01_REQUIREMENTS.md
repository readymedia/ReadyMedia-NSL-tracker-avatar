# 01 â€“ Requirements & Goals

## ğŸ¯ PrimÃ¦rmÃ¥l (MVP - Phase 1)

Bygge en lokal Windows-app (kraftig NVIDIA GPU) som:

### 1. Inndata og ingest
- âœ… Leser manifest-CSV (`minetegn_manifest_app_excel.csv`)
- âœ… Validerer at alle `local_path` finnes
- âœ… HÃ¥ndterer Ã¦Ã¸Ã¥ korrekt (NFC normalisering)
- âœ… Autodetekterer CSV-format (`,` vs `;`, encoding)

### 2. Batch-prosessering
- âœ… Prosesserer alle 9000+ videoer automatisk
- âœ… StÃ¸tter resume (hopper over allerede prosesserte)
- âœ… Parallellisering (design for, men MVP kan vÃ¦re serial)
- âœ… Robust feilhÃ¥ndtering (Ã©n feil stopper ikke hele batchen)

### 3. Tracking-ekstraksjon
Ekstrahere per frame:
- **Kropp**: pose keypoints (overkropp, armer, hender)
- **Hender**: 21 landmarks per hÃ¥nd (MediaPipe eller bedre)
- **Ansikt**: ansiktslandmarks + munn (non-manual markers)
- **Kvalitet**: confidence scores per modalitet

### 4. Datalagring
- âœ… **Lokal Supabase** (Postgres): metadata, job-status, sÃ¸k
- âœ… **Disk**: tracking data (parquet/jsonl.gz)
- âœ… Strukturert og gjenopprettbart

### 5. Eksport (Unreal-ready)
Per ord genereres:
- `tracking.jsonl.gz` (eller `tracking_v2.jsonl.gz` i Phase 2)
- `meta.json` (video metadata + quality score)
- `unreal_import.py` (Python script for Unreal)
- `index_entry.json` (for eksport-katalog)

### 6. MetaHuman-animasjon
GjÃ¸re at vi kan:
- Importere eksportpakker til Unreal
- Lage AnimSequence-assets per ord
- Trigge MetaHuman-avatar pÃ¥ ord og spille av animasjon

---

## ğŸ¯ SekundÃ¦rmÃ¥l (etter MVP)

### Kvalitetsforbedringer
- Auto cleanup av tracking (smoothing, outlier removal)
- Quality scoring per klipp (tracking quality, visibility)
- Automatisk flagging av dÃ¥rlige opptak

### Infrastruktur
- StÃ¸tte for Ã¥ bytte fra `remote_url` til egen CDN
- Versjoner av tracking (v1, v2, v3...)
- Migrering mellom formater

### Avansert tracking (Phase 2)
- Multi-model ensemble (OpenPose + MediaPipe + ...)
- Temporal stabilisering (EMA, Kalman, gap-filling)
- Super-resolution pÃ¥ lavopplÃ¸ste klipp

### Unreal-integrasjon (Phase 2.1)
- Ferdig Control Rig mapping for MetaHuman
- Automatisk bone + curve keyframe baking
- DataTable for word â†’ AnimSequence lookup

---

## ğŸ“¦ Leveranser (hva Cursor skal produsere)

### 1. Kildekode (`tracker_app/`)
Python-pakke med:
- **CLI** (Typer-basert): `ingest`, `run`, `export-index`, `export-metahuman`
- **Pipeline-moduler**:
  - `ingest/` â€“ manifest reading, job creation
  - `preprocess/` â€“ ffmpeg utils, normalization, ROI
  - `tracking/` â€“ provider interface + MediaPipe implementation
  - `postprocess/` â€“ smoothing, quality scoring
  - `store/` â€“ disk + Supabase persistence
  - `export/` â€“ Unreal package generation
  - `rig/` â€“ hand rotation solver, face curve mapping (Phase 2.1)
  - `unreal/` â€“ import script templates
- **Utils**: paths, text, hashing, logging

### 2. Database schema
- `schema.sql` â€“ full schema
- `migrations/` â€“ versjonerte SQL-migrasjoner

### 3. Konfigurasjon
- `.env.example` â€“ template for lokal setup
- `config.py` â€“ lesing av miljÃ¸variabler
- `configs/metahuman_mapping_nsl.json` â€“ MetaHuman mapping (Phase 2.1)

### 4. Scripts
PowerShell-scripts for enkel kjÃ¸ring:
- `run_supabase_local.ps1`
- `run_all.ps1`
- `run_subset.ps1`

### 5. Tester
- Unit tests for core logic
- Integration tests for full pipeline (subset av data)

### 6. Dokumentasjon
- `README.md` â€“ Quick start
- `docs/` â€“ Detaljert dokumentasjon

### 7. Outputformat-definisjon
- JSON schema for tracking data
- Naming conventions
- Versjonering

### 8. Unreal import demo
- Testpakke med 5â€“10 ord som proof-of-concept
- Fungerende import til Unreal (kan ha manuelle steg, men skal vÃ¦re dokumentert)

---

## ğŸ” Scope (hva er INNENFOR og UTENFOR)

### âœ… Innenfor scope

#### MVP (Phase 1)
- Lokal batch-prosessering
- MediaPipe tracking (kropp + hender + ansikt)
- Basis smoothing og outlier removal
- Supabase local + disk lagring
- Eksport til disk i strukturert format
- Skeleton Unreal import script (mÃ¥ testes manuelt i Unreal)

#### Phase 2
- Multi-model tracking (OpenPose + MediaPipe)
- Temporal stabilisering (EMA, velocity clamp, gap-filling)
- Quality scoring v2
- Super-resolution pÃ¥ hÃ¥nd-ROI (valgfritt)

#### Phase 2.1
- Fully functional Unreal Python import script
- MetaHuman Control Rig mapping (bones + curves)
- AnimSequence creation med keyframes

### âŒ Utenfor scope (i hvert fall for nÃ¥)

- **Tekst-til-tegnsprÃ¥k** (generativ AI)
- **Real-time tracking** (alt er offline batch)
- **Cloud hosting** (alt lokalt)
- **Generative modeller** (kun motion capture, ikke syntese)
- **Automatisk Unreal trigger-system** (mÃ¥ bygges separat i Unreal)
- **Web-frontend** (kun CLI i MVP)
- **3D rekonstruksjon** (kun 2Dâ†’3D lifting der nÃ¸dvendig)

---

## ğŸ“Š Success Criteria

### Teknisk
- [x] Pipeline kjÃ¸rer lokalt uten crashes
- [x] 95%+ av videoer prosesseres uten fatal feil
- [x] Tracking data er stabil og gjenopprettbar
- [x] Unreal-import fungerer pÃ¥ testdatasett

### Kvalitet
- [x] Hender er synlige og sporbare i 80%+ av frames
- [x] Ansikt/munn er synlig i 70%+ av frames
- [x] Quality score korrelerer med visuell kvalitet

### Performance
- [x] Prosessering: ~5â€“30 sekunder per video (avhengig av lengde/kvalitet)
- [x] Batch: fullfÃ¸re 1000 videoer pÃ¥ <24 timer (single GPU)
- [x] Database query: <100ms for typiske oppslag

### Brukbarhet
- [x] CLI er selvforklarende og loggfÃ¸rer godt
- [x] Feil er forstÃ¥elige og actionable
- [x] Resume fungerer pÃ¥litelig

---

## ğŸš§ Kjente begrensninger og risiko

### HÃ¸y risiko
1. **HÃ¥nd/finger-presisjon fra 2D video**
   - HÃ¥ndoverlapp, okklusjon, dÃ¥rlig belysning
   - *Mitigering*: Multi-model ensemble, confidence gating
   
2. **"Plug rett inn i MetaHuman"**
   - Kompleks mapping mellom tracking â†’ Control Rig
   - *Mitigering*: Iterativ tilnÃ¦rming, data-drevet mapping

### Medium risiko
3. **Varierende videokvalitet**
   - Eldre klipp er lavopplÃ¸selige
   - *Mitigering*: Super-resolution pass (valgfritt), quality scoring

4. **Temporal instabilitet**
   - Jitter, dropout, sudden jumps
   - *Mitigering*: Smoothing pipeline, gap-filling

### Lav risiko
5. **Performance pÃ¥ 9000+ filer**
   - Lang kjÃ¸retid
   - *Mitigering*: Parallellisering, GPU batch optimization

---

## ğŸ“‹ Ikke-funksjonelle krav

### Ytelse
- Skal kjÃ¸re pÃ¥ single-workstation (ikke cluster)
- GPU utilization >70% under tracking
- Minimal I/O wait (bruk SSD)

### Sikkerhet
- Ingen data forlater maskinen
- GDPR-compliant (all prosessering lokal)

### Vedlikeholdbarhet
- Kode er typed (mypy-ready)
- ModulÃ¦r arkitektur (lett Ã¥ bytte tracking-provider)
- Versjonerte output-formater

### Dokumentasjon
- README med quick start
- Docstrings pÃ¥ alle public APIs
- Cursor-optimaliserte master prompts

---

## ğŸ”„ Iterasjonsplan

### Fase 1: Foundation (Cursor session 1â€“2)
- Repo structure
- Ingest + preprocessing
- MediaPipe tracking (baseline)
- Disk + Supabase lagring

### Fase 2: Quality (Cursor session 3â€“4)
- Multi-model tracking
- Temporal stabilization
- Quality scoring

### Fase 3: MetaHuman (Cursor session 5â€“6)
- Hand rotation solver
- Face curve mapping
- Unreal import script
- Full test pÃ¥ 10+ ord

### Fase 4: Batch (Cursor session 7)
- Full batch-kjÃ¸ring (9000 videoer)
- Performance tuning
- Failure analysis

---

**Neste: [02_ARCHITECTURE.md](02_ARCHITECTURE.md) â†’**
